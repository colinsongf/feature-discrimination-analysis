{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "import patsy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import basinhopping\n",
    "from sklearn import linear_model\n",
    "import multiprocessing\n",
    "##Code for analysis of fMRI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rew_trial_1 = [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "trial_order_1 = [1, 2, 10, 6, 10, 6, 10, 4, 5, 10, 1, 2, 10, 3, 10, 1, 2, 10, 1, 2, 10, 1, 2, 10, 4, 5, 10, 4, 5, 10, 3, 10, 1, 2, 10, 4, 5, 10, 4, 5, 10, 6, 10, 3, 10, 4, 5, 10, 6, 10, 3, 10, 3, 10, 6, 10, 4, 5, 10, 3, 10, 6, 10, 1, 2, 10, 3, 10, 1, 2, 10, 4, 5, 10, 4, 5, 10, 6, 10, 3, 10, 6, 10, 1, 2, 10, 3, 10, 6, 10, 3, 10, 4, 5, 10, 6, 10, 1, 2, 10]\n",
    "            \n",
    "rew_trial_2 = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "trial_order_2 = [4, 5, 10, 3, 10, 4, 5, 10, 4, 5, 10, 1, 2, 10, 3, 10, 3, 10, 4, 5, 10, 4, 5, 10, 1, 2, 10, 6, 10, 1, 2, 10, 6, 10, 6, 10, 4, 5, 10, 4, 5, 10, 1, 2, 10, 3, 10, 6, 10, 6, 10, 6, 10, 4, 5, 10, 3, 10, 1, 2, 10, 6, 10, 1, 2, 10, 1, 2, 10, 1, 2, 10, 3, 10, 4, 5, 10, 1, 2, 10, 6, 10, 3, 10, 3, 10, 3, 10, 6, 10, 4, 5, 10, 3, 10, 6, 10, 1, 2, 10]\n",
    "                \n",
    "rew_trial_3 = [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "trial_order_3 = [1, 2, 10, 6, 10, 6, 10, 3, 10, 3, 10, 6, 10, 1, 2, 10, 1, 2, 10, 3, 10, 3, 10, 4, 5, 10, 4, 5, 10, 1, 2, 10, 6, 10, 3, 10, 6, 10, 4, 5, 10, 4, 5, 10, 4, 5, 10, 3, 10, 1, 2, 10, 4, 5, 10, 4, 5, 10, 6, 10, 3, 10, 4, 5, 10, 1, 2, 10, 1, 2, 10, 1, 2, 10, 4, 5, 10, 6, 10, 3, 10, 1, 2, 10, 3, 10, 6, 10, 6, 10, 3, 10, 4, 5, 10, 1, 2, 10, 6, 10]\n",
    "\n",
    "rew_trial_1_sim = [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
    "trial_order_1_sim = [2, 10, 2, 10, 4, 10, 2, 10, 4, 10, 4, 10, 3, 10, 4, 10, 3, 10, 2, 10, 1, 10, 2, 10, 4, 10, 1, 10, 3, 10, 3, 10, 3, 10, 4, 10, 4, 10, 1, 10, 4, 10, 3, 10, 1, 10, 3, 10, 1, 10, 2, 10, 1, 10, 2, 10, 3, 10, 2, 10, 1, 10, 3, 10, 1, 10, 4, 10, 1, 10, 2, 10, 2, 10, 3, 10, 1, 10, 4, 10]\n",
    "\n",
    "rew_trial_2_sim = [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
    "trial_order_2_sim = [1, 10, 4, 10, 1, 10, 4, 10, 4, 10, 1, 10, 3, 10, 3, 10, 1, 10, 2, 10, 1, 10, 4, 10, 1, 10, 3, 10, 4, 10, 4, 10, 2, 10, 1, 10, 1, 10, 3, 10, 2, 10, 3, 10, 2, 10, 3, 10, 4, 10, 1, 10, 3, 10, 2, 10, 2, 10, 3, 10, 2, 10, 4, 10, 2, 10, 4, 10, 3, 10, 2, 10, 2, 10, 1, 10, 4, 10, 3, 10]\n",
    "\n",
    "rew_trial_3_sim = [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
    "trial_order_3_sim = [1, 10, 2, 10, 4, 10, 1, 10, 4, 10, 2, 10, 2, 10, 1, 10, 4, 10, 4, 10, 4, 10, 1, 10, 3, 10, 1, 10, 2, 10, 1, 10, 3, 10, 3, 10, 3, 10, 2, 10, 3, 10, 4, 10, 3, 10, 1, 10, 4, 10, 3, 10, 4, 10, 2, 10, 2, 10, 4, 10, 3, 10, 2, 10, 3, 10, 1, 10, 2, 10, 1, 10, 2, 10, 1, 10, 4, 10, 3, 10]\n",
    "\n",
    "rew = np.hstack([rew_trial_1,rew_trial_2,rew_trial_3,rew_trial_1_sim,rew_trial_2_sim,rew_trial_3_sim])\n",
    "trial_order = np.hstack([trial_order_1,trial_order_2,trial_order_3,\\\n",
    "                         trial_order_1_sim,trial_order_2_sim,trial_order_3_sim])\n",
    "run = np.hstack([ [1]*len(rew_trial_1), [2]*len(rew_trial_1), [3]*len(rew_trial_1),\\\n",
    "                 [1]*len(rew_trial_1_sim),[2]*len(rew_trial_1_sim), [3]*len(rew_trial_1_sim)])\n",
    "exp = np.hstack([['ser']*len(rew_trial_1)*3, ['sim']*len(rew_trial_1_sim)*3])\n",
    "data = {'rew': rew, 'trial_order': trial_order, 'run': run, 'exp':exp}\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(data_dir+ '/exp_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     exp  rew  run  trial_order\n",
      "0    ser    0    1            1\n",
      "1    ser    0    1            2\n",
      "2    ser    0    1           10\n",
      "3    ser    1    1            6\n",
      "4    ser    0    1           10\n",
      "5    ser    1    1            6\n",
      "6    ser    0    1           10\n",
      "7    ser    0    1            4\n",
      "8    ser    1    1            5\n",
      "9    ser    0    1           10\n",
      "10   ser    0    1            1\n",
      "11   ser    1    1            2\n",
      "12   ser    0    1           10\n",
      "13   ser    0    1            3\n",
      "14   ser    0    1           10\n",
      "15   ser    0    1            1\n",
      "16   ser    1    1            2\n",
      "17   ser    0    1           10\n",
      "18   ser    0    1            1\n",
      "19   ser    1    1            2\n",
      "20   ser    0    1           10\n",
      "21   ser    0    1            1\n",
      "22   ser    1    1            2\n",
      "23   ser    0    1           10\n",
      "24   ser    0    1            4\n",
      "25   ser    0    1            5\n",
      "26   ser    0    1           10\n",
      "27   ser    0    1            4\n",
      "28   ser    0    1            5\n",
      "29   ser    0    1           10\n",
      "..   ...  ...  ...          ...\n",
      "510  sim    0    3            3\n",
      "511  sim    0    3           10\n",
      "512  sim    1    3            4\n",
      "513  sim    0    3           10\n",
      "514  sim    0    3            2\n",
      "515  sim    0    3           10\n",
      "516  sim    0    3            2\n",
      "517  sim    0    3           10\n",
      "518  sim    1    3            4\n",
      "519  sim    0    3           10\n",
      "520  sim    0    3            3\n",
      "521  sim    0    3           10\n",
      "522  sim    1    3            2\n",
      "523  sim    0    3           10\n",
      "524  sim    0    3            3\n",
      "525  sim    0    3           10\n",
      "526  sim    1    3            1\n",
      "527  sim    0    3           10\n",
      "528  sim    0    3            2\n",
      "529  sim    0    3           10\n",
      "530  sim    1    3            1\n",
      "531  sim    0    3           10\n",
      "532  sim    1    3            2\n",
      "533  sim    0    3           10\n",
      "534  sim    0    3            1\n",
      "535  sim    0    3           10\n",
      "536  sim    0    3            4\n",
      "537  sim    0    3           10\n",
      "538  sim    1    3            3\n",
      "539  sim    0    3           10\n",
      "\n",
      "[540 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "data_dir = os.path.abspath('../')\n",
    "all_rts = pd.read_csv(data_dir + '/all_rts.csv', index_col =0)\n",
    "exp_order = pd.read_csv(data_dir + '/exp_order.csv', index_col =0)\n",
    "subjects = list(np.loadtxt(data_dir+ '/subjects.txt',str))\n",
    "print exp_order\n",
    "#some experiment variables\n",
    "order_dict_ser = {'c_plus':6, 'b_plus':2, 'b_minus':3, 'c_minus':5} #coding for trial order vector\n",
    "order_dict_sim = {'c_plus':6, 'b_plus':2, 'b_minus':3, 'c_minus':5}\n",
    "order_dict_exp = {'ser': order_dict_ser, 'sim':order_dict_sim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process the RTs a bit (remove trial types 1, 4, and 10 (see below) and mean center)\n",
    "ser_rts = all_rts[all_rts['exp']=='ser']\n",
    "ser_rts = ser_rts[ser_rts['order'] != 10] #ITI\n",
    "ser_rts = ser_rts[ser_rts['order'] != 1] #A\n",
    "ser_rts = ser_rts[ser_rts['order'] != 4] #A\n",
    "\n",
    "sim_rts = all_rts[all_rts['exp']=='sim']\n",
    "sim_rts = sim_rts[sim_rts['order'] != 10] #ITI\n",
    "\n",
    "rt_dict_exp = {'ser': ser_rts, 'sim':sim_rts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#made a mistake labeling these subject files. See notes\n",
    "def get_sub_id(sub):        \n",
    "    if sub == 'fd_126':\n",
    "        sub_id = 'fd_125'\n",
    "    elif sub == 'fd_127':\n",
    "        sub_id = 'fd_126'\n",
    "    else:\n",
    "        sub_id = sub\n",
    "    return sub_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_RL(trial_order,rew_trial,exp,alpha):\n",
    "    V = {'b_plus':[0], 'b_minus' : [0], 'c_plus' : [0],'c_minus':[0]}\n",
    "    delta = {'b_plus':[], 'b_minus' : [], 'c_plus' : [],'c_minus':[]}\n",
    "    index = {'b_plus':[], 'b_minus' : [], 'c_plus' : [],'c_minus':[]}\n",
    "    order_dict = order_dict_exp[exp]\n",
    "    count = 0\n",
    "    for n,cond in enumerate(trial_order):\n",
    "        trial_type = None\n",
    "        for key in order_dict:\n",
    "            if order_dict[key] == cond:\n",
    "                trial_type = key\n",
    "        \n",
    "        if trial_type is not None:\n",
    "            rew = rew_trial[n]\n",
    "            delta[trial_type].append(rew - V[trial_type][-1]) #compute PE\n",
    "            new_V = V[trial_type][-1] + alpha * delta[trial_type][-1] #calculate V for next trial\n",
    "            V[trial_type].append(new_V) \n",
    "            index[trial_type].append(count)\n",
    "            count += 1 \n",
    "\n",
    "    return V, delta, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##function for building dataframe of relevant data for each subject\n",
    "def build_df(sub,num_runs,exp):\n",
    "    alpha = .1 #just some arbitrary alpha to get things going\n",
    "    order_dict = order_dict_exp[exp]\n",
    "    predictors = {'V':[],'PE':[],'run':[], 'cond':[], 'trial_index':[],'rt':[]}\n",
    "    for i in range(1,num_runs+1):\n",
    "        ##perform RL for the experimental condition\n",
    "        rew = np.array(exp_order[exp_order['run']==i]['rew'])\n",
    "        tt = np.array(exp_order[exp_order['run']==i]['trial_order'])\n",
    "        V, delta, index = perform_RL(tt,rew,alpha)\n",
    "\n",
    "        #get rt data for this subject and run\n",
    "        rts = rt_dict_exp[exp]\n",
    "        rt_data = rts[(rts['sub']==sub) & (rts['run']==i) ]\n",
    "        \n",
    "        ##update predictors dict\n",
    "        for key in V.keys():\n",
    "            V[key] = V[key][:-1] #last entry is for subsequent trial that doesnt exist\n",
    "            predictors['V'].extend(V[key])\n",
    "            predictors['PE'].extend(delta[key])\n",
    "            predictors['cond'].extend([key]*len(V[key]))\n",
    "            predictors['run'].extend(['run' + str(i)]*len(V[key]))\n",
    "            predictors['trial_index'].extend(index[key])\n",
    "            predictors['rt'].extend(rt_data[rt_data['order']==order_dict[key]]['rt'].values)\n",
    "\n",
    "    predictors = pd.DataFrame(predictors)\n",
    "    predictors = predictors.sort(['run','trial_index']) #get predictors in proper order\n",
    "\n",
    "    #mean center RT\n",
    "    predictors['rt'] = predictors['rt'] - predictors['rt'].mean()\n",
    "\n",
    "    #Z-score trial index for each row\n",
    "    for i in range(1,num_runs+1):\n",
    "        run = 'run' + str(i)\n",
    "        predictors.loc[predictors['run']==run,'trial_index'] =  predictors.loc[predictors['run']==run,'trial_index'] - \\\n",
    "        predictors.loc[predictors['run']==run,'trial_index'].mean()\n",
    "        predictors.loc[predictors['run']==run,'trial_index'] =  predictors.loc[predictors['run']==run,'trial_index'] / \\\n",
    "        predictors.loc[predictors['run']==run,'trial_index'].std()\n",
    "    \n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##returns loss for linear regression\n",
    "def regress(params,predictors,num_runs):\n",
    "    \n",
    "    alpha = params[0] #learning rate\n",
    "    beta = params[1:]\n",
    "    \n",
    "    ##perform RL for the experimental condition\n",
    "    for i in range(1,num_runs+1):\n",
    "        rew = np.array(exp_order[exp_order['run']==i]['rew'])\n",
    "        tt = np.array(exp_order[exp_order['run']==i]['trial_order'])\n",
    "        V, delta, index = perform_RL(tt,rew,alpha)\n",
    "        for key in V.keys():\n",
    "            V[key] = V[key][:-1] #last entry is for subsequent trial that doesnt exist\n",
    "            predictors.loc[(predictors['run'] == 'run' + str(i)) & (predictors['cond'] == key),'V'] = V[key]\n",
    "            predictors.loc[(predictors['run'] == 'run' + str(i)) & (predictors['cond'] == key),'PE'] = delta[key]\n",
    "\n",
    "            \n",
    "    #build RL matrixes\n",
    "    yd,Xd = patsy.dmatrices(\"rt ~ 1+trial_index+V+run\",predictors,NA_action='drop')\n",
    "    X = np.asarray(Xd)\n",
    "    y=np.array(map(float,np.asarray(yd)))\n",
    "\n",
    "    #compute prediction and loss\n",
    "    y_hat = np.dot(X,beta)\n",
    "    loss = np.linalg.norm(y - y_hat)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_df() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ad9d24288efe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#initialize parameters to 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#initialize parameters to 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: build_df() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "params = np.transpose(np.zeros(X.shape[1]+1)) #initialize parameters to 0\n",
    "params = (.1,0,0,0,0,0) #initialize parameters to 0\n",
    "\n",
    "bounds = ((0,1),(None,None),(None,None),(None,None),(None,None),(None,None))\n",
    "#res = minimize(regress, params, method='Powell',options={'disp': True})\n",
    "#res = minimize(regress, params, method='BFGS',options={'disp': True})\n",
    "#res = minimize(regress, params, method='SLSQP',bounds = bounds, options={'disp': True,'maxiter':200})\n",
    "\n",
    "#minimizer_kwargs = {\"method\": \"L-BFGS-B\",'bounds':bounds}\n",
    "#ret = basinhopping(regress, params, minimizer_kwargs=minimizer_kwargs,niter=50)\n",
    "\n",
    "\n",
    "res = minimize(regress,params,bounds=bounds, method='L-BFGS-B', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  status: 0\n",
       " success: True\n",
       "    nfev: 714\n",
       "     fun: 1718.4515853621633\n",
       "       x: array([  5.34427168e-02,  -1.04735376e+03,  -1.16936986e+01,\n",
       "         7.56606351e+00,   7.04894734e+01,   1.17886548e+03])\n",
       " message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     jac: array([-0.23917437,  0.02451088, -0.10184067, -0.02185061,  0.07646577,\n",
       "        0.01630269])\n",
       "     nit: 75"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##loop through all subjects\n",
    "def run_subjects(sub):\n",
    "    sub_id = get_sub_id(sub)\n",
    "    \n",
    "    #get predictors dataframe\n",
    "    num_runs = len(np.unique(ser_rts[ser_rts['sub']==sub_id]['run']))\n",
    "    predictors = build_df(sub_id,num_runs)\n",
    "\n",
    "    #initialize\n",
    "    params = (.1,0,0,0,0,0) #initialize parameters to 0\n",
    "    bounds = ((0,1),(None,None),(None,None),(None,None),(None,None),(None,None))\n",
    "\n",
    "    #minimize\n",
    "#     res = minimize(regress,params,args=(predictors,num_runs),bounds=bounds, method='L-BFGS-B', options={'disp': True})\n",
    "    \n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pool = multiprocessing.Pool(processes=30)\n",
    "# output = pool.map(run_subjects,subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.84678794e-01   5.51152531e+01   2.25771659e+01   2.41422568e+01\n",
      "   9.53527392e+00  -1.03489958e+03]\n",
      "[  3.33529795e-01   7.59497829e+01   6.06802264e+01   7.94340480e+01\n",
      "   3.14376574e+01   2.06234191e+03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  2.,  4.,  4.,  4.,  6.,  2.,  1.,  2.]),\n",
       " array([-57.33210137, -44.27721909, -31.22233681, -18.16745453,\n",
       "         -5.11257225,   7.94231003,  20.99719231,  34.05207459,\n",
       "         47.10695688,  60.16183916,  73.21672144]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEDCAYAAAAVyO4LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJkpa2/wF7w3pwf7EWFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff830774150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = []\n",
    "for n,o in enumerate(output):\n",
    "    if o.success:\n",
    "        params.append(o.x)    \n",
    "params = np.array(params)\n",
    "\n",
    "print np.mean(params, axis=0)\n",
    "print np.std(params,axis = 0)\n",
    "plt.hist(params[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.52411454, -13.38725855,  11.71133923,  -9.9083914 ,  24.31352455])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check that linear regression code works (given a fixed alpha)\n",
    "clf = linear_model.LinearRegression(fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now try to fit all subjects' data simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##function for building dataframe of relevant data for each subject\n",
    "def build_df_all(num_runs, exp):\n",
    "    order_dict = order_dict_exp[exp]\n",
    "    alpha = .1\n",
    "    predictors = {'subject':[],'V':[],'PE':[],'run':[], 'cond':[], 'trial_index':[],'rt':[]}\n",
    "\n",
    "    for i in range(1,num_runs+1):\n",
    "\n",
    "        ##perform RL for the experimental condition\n",
    "        rew = np.array(exp_order[exp_order['run']==i]['rew'])\n",
    "        tt = np.array(exp_order[exp_order['run']==i]['trial_order'])\n",
    "        V, delta, index = perform_RL(tt,rew,alpha)\n",
    "        for key in V.keys():\n",
    "            V[key] = V[key][:-1] #last entry is for subsequent trial that doesnt exist\n",
    "\n",
    "        for sub in subjects:\n",
    "            sub_id = get_sub_id(sub)\n",
    "    \n",
    "            #get rt data for this subject and run\n",
    "            rts = rt_dict_exp[exp]\n",
    "            rt_data = rts[(rts['sub']==sub_id) & (rts['run']==i) ]\n",
    "\n",
    "            ##update predictors dict\n",
    "            for key in V.keys():\n",
    "                if len(rt_data[rt_data['order']==order_dict[key]]['rt'].values) != 10:\n",
    "                    print len(rt_data[rt_data['order']==order_dict[key]]['rt'].values)\n",
    "                    print i\n",
    "                    print sub\n",
    "                predictors['V'].extend(V[key])\n",
    "                predictors['PE'].extend(delta[key])\n",
    "                predictors['cond'].extend([key]*len(V[key]))\n",
    "                predictors['subject'].extend([sub]*len(V[key]))\n",
    "                predictors['run'].extend(['run' + str(i)]*len(V[key]))\n",
    "                predictors['trial_index'].extend(index[key])\n",
    "                predictors['rt'].extend(rt_data[rt_data['order']==order_dict[key]]['rt'].values)\n",
    "\n",
    "    predictors = pd.DataFrame(predictors)\n",
    "    predictors = predictors.sort(['subject','run','trial_index']) #get predictors in proper order\n",
    "\n",
    "    #mean center RT\n",
    "#     predictors['rt'] = predictors['rt'] - predictors['rt'].mean()\n",
    "    \n",
    "    #Z score RT for each subject\n",
    "    for sub in subjects:\n",
    "        predictors.loc[predictors['subject']==sub,'rt'] =  predictors.loc[predictors['subject']==sub,'rt'] - \\\n",
    "        predictors.loc[predictors['subject']==sub,'rt'].mean()  \n",
    "        predictors.loc[predictors['subject']==sub,'rt'] =  predictors.loc[predictors['subject']==sub,'rt'] / \\\n",
    "        predictors.loc[predictors['subject']==sub,'rt'].std() \n",
    "        \n",
    "    #Z-score trial index for each row\n",
    "    for i in range(1,num_runs+1):\n",
    "        run = 'run' + str(i)\n",
    "        predictors.loc[predictors['run']==run,'trial_index'] =  predictors.loc[predictors['run']==run,'trial_index'] - \\\n",
    "        predictors.loc[predictors['run']==run,'trial_index'].mean()\n",
    "        predictors.loc[predictors['run']==run,'trial_index'] =  predictors.loc[predictors['run']==run,'trial_index'] / \\\n",
    "        predictors.loc[predictors['run']==run,'trial_index'].std()\n",
    "    \n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##returns loss for linear regression\n",
    "def regress_all(params,predictors,num_runs):\n",
    "    \n",
    "    alpha = params[0] #learning rate\n",
    "    beta = params[1:]\n",
    "\n",
    "    ##perform RL for the experimental condition\n",
    "    for i in range(1,num_runs+1):\n",
    "        rew = np.array(exp_order[exp_order['run']==i]['rew'])\n",
    "        tt = np.array(exp_order[exp_order['run']==i]['trial_order'])\n",
    "        V, delta, index = perform_RL(tt,rew,alpha)\n",
    "        for key in V.keys():\n",
    "            V[key] = V[key][:-1] #last entry is for subsequent trial that doesnt exist \n",
    "            predictors.ix[(predictors['run'] == 'run' + str(i)) & (predictors['cond'] == key) ,'V'] = V[key]*len(subjects)\n",
    "            predictors.ix[(predictors['run'] == 'run' + str(i)) & (predictors['cond'] == key),'PE'] = delta[key]*len(subjects)\n",
    "    \n",
    "    #build RL matrixes\n",
    "    yd,Xd = patsy.dmatrices(\"rt ~ 1+trial_index+V+run\",predictors,NA_action='drop')\n",
    "    X = np.asarray(Xd)\n",
    "    y=np.array(map(float,np.asarray(yd)))\n",
    "\n",
    "    #compute prediction and loss\n",
    "    y_hat = np.dot(X,beta)\n",
    "    loss = np.linalg.norm(y - y_hat)\n",
    "    return loss\n",
    "# regress_all(params,predictors,num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [.1]\n",
    "params.extend(np.zeros(5))\n",
    "num_runs  = 3\n",
    "predictors = build_df_all(num_runs)\n",
    "loss = regress_all(params,predictors,num_runs)\n",
    "bounds = [(0,1)]\n",
    "for i in range(0,5):\n",
    "    bounds.append((None,None))\n",
    "\n",
    "#minimize\n",
    "# res = minimize(regress_all,params,args=(predictors,num_runs),bounds=bounds, method='L-BFGS-B', options={'disp': True})\n",
    "minimizer_kwargs = {\"method\": \"L-BFGS-B\",'bounds':bounds,'args':(predictors,num_runs)}\n",
    "ret = basinhopping(regress_all, params, minimizer_kwargs=minimizer_kwargs,niter=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  status: 0\n",
       " success: True\n",
       "    nfev: 140\n",
       "     fun: 37.446722033040068\n",
       "       x: array([ 0.38248941,  0.36202189,  0.12028357,  0.15694242,  0.00447452,\n",
       "       -1.11603443])\n",
       " message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     jac: array([ -5.11590770e-05,  -1.64135372e-04,  -1.30739863e-04,\n",
       "         6.67910172e-05,  -2.48689958e-05,   0.00000000e+00])\n",
       "     nit: 16"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  nfev: 7196\n",
       " minimization_failures: 0\n",
       "                   fun: 37.446722031145107\n",
       "                     x: array([ 0.38249334,  0.36203726,  0.12028474,  0.15693011,  0.00447598,\n",
       "       -1.11605044])\n",
       "               message: ['requested number of basinhopping iterations completed successfully']\n",
       "                   nit: 50"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  nfev: 7098\n",
       " minimization_failures: 0\n",
       "                   fun: 37.446722031143729\n",
       "                     x: array([ 0.38249235,  0.36203817,  0.12028541,  0.15692999,  0.00447623,\n",
       "       -1.11605292])\n",
       "               message: ['requested number of basinhopping iterations completed successfully']\n",
       "                   nit: 50"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
